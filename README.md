# A Horse in DA-ConvNets: AT-Net


<a href="https://www.youtube.com/shorts/3BW1lBgtbbs" class="follow"> 
<img align="left" width="350" height="200" src="at_net.JPG"> 
</a>
This is actually a less serious weekend project called AT-Net which can be thought as a variation on Mobile-Net architecture. We start with a convolutional layer then use seperable convolutions. Finally use some encoder type transformer layers. Together with some register tokens and a class token. The convolution part is highly motivated by "Patches are all you need paper". This dude is trained on ImageNet1k dataset, we offer three different sizes: XS, S, L. 
Our motto in AT-Net:
1) We do something because we want that thing!!!,
2) No promise to get very high accuracy,
3) No proimes to bear someoneelse's model,
4) We like to hybridize things,
Enjoy AT-Net!!!

# Training Details
# Optimizers
# Epochs - Batch Size


I have reached --- accuracy on ---, and guess this happened where, at home on two GPUs!!!

