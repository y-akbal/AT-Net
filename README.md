# Variations-on-Mobile-Net

Here is a variation on Mobile-Net architecture, I have added some intermediate attention layers that are a bit different 
than the conventional attention layers.

I have reached --- accuracy on ---, and guess this happened where, at home on two GPUs!!!

