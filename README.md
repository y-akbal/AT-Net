# AT-Net

Here is a variation on Mobile-Net architecture, 
We start with conventional convolutional layer then used seperable convolutions. Finally use some encoder type transformer layers. The convolution part is highly motivated by Patches are all you need paper.
Enjoy AT-Net.

I have reached --- accuracy on ---, and guess this happened where, at home on two GPUs!!!

